{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 处理前的准备**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 确保输出目录存在"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建或确认 ..\\data\\advanced_analysis_results 目录成功\n",
      "✅ 成功加载 cleaned_data\n"
     ]
    }
   ],
   "source": [
    "input_path = Path('../data/interim/cleaned_data.pkl')\n",
    "base_output_dir = Path(\"../data/advanced_analysis_results\")\n",
    "\n",
    "# 确保输出目录存在\n",
    "try:\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "    print(f\"创建或确认 {base_output_dir} 目录成功\")\n",
    "except Exception as e:\n",
    "    print(f\"创建 {base_output_dir} 目录失败: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 加载 cleaned_data\n",
    "input_path = Path('../data/interim/cleaned_data.pkl')\n",
    "if input_path.exists():\n",
    "    with open(input_path, 'rb') as f:\n",
    "        cleaned_data = pickle.load(f)\n",
    "    print(\"✅ 成功加载 cleaned_data\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"未找到 cleaned_data.pkl，请先运行 02-cleaning.ipynb 并保存数据\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 初始化分析结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results = {\n",
    "    \"rating_trends\": {},\n",
    "    \"rating_feature_relations\": {},\n",
    "    \"interest_cycles\": {},\n",
    "    \"consumption_speed\": {},\n",
    "    \"genre_cooccurrence\": {},\n",
    "    \"rating_prediction\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 分析处理**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 评分趋势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_rating_trends(df, category, sheet_name):\n",
    "    trends = {\"douban_rating\": {}, \"my_rating\": {}}\n",
    "    if '创建时间' in df.columns and '豆瓣评分' in df.columns:\n",
    "        df['创建时间'] = pd.to_datetime(df['创建时间'], errors='coerce')\n",
    "        df['季度'] = df['创建时间'].dt.to_period('Q')\n",
    "        # 豆瓣评分\n",
    "        douban_trend = df.groupby('季度')['豆瓣评分'].agg(['mean', 'count']).dropna()\n",
    "        trends[\"douban_rating\"] = {str(k): {\"mean\": float(v['mean']), \"count\": int(v['count'])} for k, v in douban_trend.iterrows()}\n",
    "        # 我的评分（10分制）\n",
    "        if '我的评分' in df.columns:\n",
    "            df['我的评分_10'] = pd.to_numeric(df['我的评分'], errors='coerce') * 2\n",
    "            my_trend = df.groupby('季度')['我的评分_10'].agg(['mean', 'count']).dropna()\n",
    "            trends[\"my_rating\"] = {str(k): {\"mean\": float(v['mean']), \"count\": int(v['count'])} for k, v in my_trend.iterrows()}\n",
    "    return trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析评分趋势\n",
    "for category, sheet in [(\"movies\", \"看过\"), (\"books\", \"读过\"), (\"games\", \"玩过\")]:\n",
    "    if sheet in cleaned_data:\n",
    "        analysis_results[\"rating_trends\"][category] = analyze_rating_trends(cleaned_data[sheet], category, sheet)\n",
    "    else:\n",
    "        analysis_results[\"rating_trends\"][category] = {\"note\": f\"未找到 {sheet} 数据\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📈 Movies 评分趋势：\n",
      "  豆瓣评分（前3个季度）：\n",
      "    - 2021Q1: 平均 8.45, 数量 2\n",
      "    - 2021Q4: 平均 8.21, 数量 21\n",
      "    - 2022Q1: 平均 8.52, 数量 14\n",
      "  我的评分（前3个季度）：\n",
      "    - 2021Q1: 平均 10.00, 数量 2\n",
      "    - 2021Q4: 平均 9.33, 数量 21\n",
      "    - 2022Q1: 平均 9.14, 数量 14\n",
      "\n",
      "📈 Books 评分趋势：\n",
      "  豆瓣评分（前3个季度）：\n",
      "    - 2022Q3: 平均 8.38, 数量 5\n",
      "    - 2023Q2: 平均 8.36, 数量 5\n",
      "    - 2023Q3: 平均 9.10, 数量 1\n",
      "  我的评分（前3个季度）：\n",
      "    - 2022Q3: 平均 9.60, 数量 5\n",
      "    - 2023Q2: 平均 8.00, 数量 5\n",
      "    - 2023Q3: 平均 8.00, 数量 1\n",
      "\n",
      "📈 Games 评分趋势：\n",
      "  豆瓣评分（前3个季度）：\n",
      "    - 2025Q2: 平均 8.70, 数量 15\n",
      "  我的评分（前3个季度）：\n",
      "    - 2025Q2: 平均 9.47, 数量 15\n"
     ]
    }
   ],
   "source": [
    "# 展示评分趋势\n",
    "for category in [\"movies\", \"books\", \"games\"]:\n",
    "    trends = analysis_results[\"rating_trends\"][category]\n",
    "    print(f\"\\n📈 {category.capitalize()} 评分趋势：\")\n",
    "    if \"note\" in trends:\n",
    "        print(f\"  {trends['note']}\")\n",
    "    else:\n",
    "        print(\"  豆瓣评分（前3个季度）：\")\n",
    "        for period, stats in list(trends[\"douban_rating\"].items())[:3]:\n",
    "            print(f\"    - {period}: 平均 {stats['mean']:.2f}, 数量 {stats['count']}\")\n",
    "        print(\"  我的评分（前3个季度）：\")\n",
    "        for period, stats in list(trends[\"my_rating\"].items())[:3]:\n",
    "            print(f\"    - {period}: 平均 {stats['mean']:.2f}, 数量 {stats['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 评分与特征关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_rating_features(df, category, sheet_name):\n",
    "    features = {\"genre\": {}, \"year\": {}, \"country\": {}}\n",
    "    if df.empty:\n",
    "        return features\n",
    "    \n",
    "    # 类型\n",
    "    if '类型' in df.columns:\n",
    "        df_exploded = df.explode('类型')\n",
    "        genre_stats = df_exploded.groupby('类型').agg({\n",
    "            '豆瓣评分': [('mean', 'mean'), ('count', 'count')],\n",
    "            '我的评分': [('my_mean', lambda x: (pd.to_numeric(x, errors='coerce') * 2).mean())]\n",
    "        }).dropna()\n",
    "        for genre, stats in genre_stats.iterrows():\n",
    "            features[\"genre\"][genre] = {\n",
    "                \"douban_mean\": float(stats[('豆瓣评分', 'mean')]) if not pd.isna(stats[('豆瓣评分', 'mean')]) else None,\n",
    "                \"my_mean\": float(stats[('我的评分', 'my_mean')]) if not pd.isna(stats[('我的评分', 'my_mean')]) else None,\n",
    "                \"count\": int(stats[('豆瓣评分', 'count')])\n",
    "            }\n",
    "    \n",
    "    # 年份（图书用出版年份）\n",
    "    year_col = '出版年份' if category == \"books\" else '年份' if category == \"movies\" else '发售时间'\n",
    "    if year_col in df.columns:\n",
    "        if year_col == '发售时间':\n",
    "            df['发售年份'] = pd.to_datetime(df['发售时间'], errors='coerce').dt.year\n",
    "            year_col = '发售年份'\n",
    "        year_stats = df.groupby(year_col).agg({\n",
    "            '豆瓣评分': [('mean', 'mean'), ('count', 'count')],\n",
    "            '我的评分': [('my_mean', lambda x: (pd.to_numeric(x, errors='coerce') * 2).mean())]\n",
    "        }).dropna()\n",
    "        for year, stats in year_stats.iterrows():\n",
    "            features[\"year\"][str(year)] = {\n",
    "                \"douban_mean\": float(stats[('豆瓣评分', 'mean')]) if not pd.isna(stats[('豆瓣评分', 'mean')]) else None,\n",
    "                \"my_mean\": float(stats[('我的评分', 'my_mean')]) if not pd.isna(stats[('我的评分', 'my_mean')]) else None,\n",
    "                \"count\": int(stats[('豆瓣评分', 'count')])\n",
    "            }\n",
    "    \n",
    "    # 国家/地区（仅影视）\n",
    "    if category == \"movies\" and '国家/地区' in df.columns:\n",
    "        df_exploded = df.explode('国家/地区')\n",
    "        country_stats = df_exploded.groupby('国家/地区').agg({\n",
    "            '豆瓣评分': [('mean', 'mean'), ('count', 'count')],\n",
    "            '我的评分': [('my_mean', lambda x: (pd.to_numeric(x, errors='coerce') * 2).mean())]\n",
    "        }).dropna()\n",
    "        for country, stats in country_stats.iterrows():\n",
    "            features[\"country\"][country] = {\n",
    "                \"douban_mean\": float(stats[('豆瓣评分', 'mean')]) if not pd.isna(stats[('豆瓣评分', 'mean')]) else None,\n",
    "                \"my_mean\": float(stats[('我的评分', 'my_mean')]) if not pd.isna(stats[('我的评分', 'my_mean')]) else None,\n",
    "                \"count\": int(stats[('豆瓣评分', 'count')])\n",
    "            }\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 分析评分与特征关系\n",
    "for category, sheet in [(\"movies\", \"看过\"), (\"books\", \"读过\"), (\"games\", \"玩过\")]:\n",
    "    if sheet in cleaned_data:\n",
    "        analysis_results[\"rating_feature_relations\"][category] = analyze_rating_features(cleaned_data[sheet], category, sheet)\n",
    "    else:\n",
    "        analysis_results[\"rating_feature_relations\"][category] = {\"note\": f\"未找到 {sheet} 数据\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔗 Movies 评分与特征关系：\n",
      "  类型（前3个）：\n",
      "    - 传记: 豆瓣 8.24, 我的评分 8.67, 数量 9\n",
      "    - 儿童: 豆瓣 7.20, 我的评分 10.00, 数量 1\n",
      "    - 冒险: 豆瓣 7.60, 我的评分 8.25, 数量 48\n",
      "  年份（前3个）：\n",
      "    - 1994: 豆瓣 9.60, 我的评分 10.00, 数量 2\n",
      "    - 1997: 豆瓣 9.15, 我的评分 10.00, 数量 2\n",
      "    - 1998: 豆瓣 9.35, 我的评分 9.00, 数量 2\n",
      "  国家/地区（前3个）：\n",
      "    - 中国台湾: 豆瓣 8.14, 我的评分 9.20, 数量 5\n",
      "    - 中国大陆: 豆瓣 7.32, 我的评分 8.38, 数量 68\n",
      "    - 中国香港: 豆瓣 7.28, 我的评分 8.42, 数量 19\n",
      "\n",
      "🔗 Books 评分与特征关系：\n",
      "  类型（前3个）：\n",
      "  年份（前3个）：\n",
      "    - 2003: 豆瓣 9.00, 我的评分 10.00, 数量 2\n",
      "    - 2006: 豆瓣 9.10, 我的评分 10.00, 数量 1\n",
      "    - 2007: 豆瓣 8.10, 我的评分 10.00, 数量 1\n",
      "\n",
      "🔗 Games 评分与特征关系：\n",
      "  类型（前3个）：\n",
      "    - 冒险: 豆瓣 8.86, 我的评分 9.20, 数量 10\n",
      "    - 动作: 豆瓣 8.92, 我的评分 9.50, 数量 8\n",
      "    - 射击: 豆瓣 8.83, 我的评分 9.33, 数量 3\n",
      "  年份（前3个）：\n",
      "    - 2007: 豆瓣 6.50, 我的评分 10.00, 数量 1\n",
      "    - 2009: 豆瓣 9.00, 我的评分 8.00, 数量 1\n",
      "    - 2011: 豆瓣 8.60, 我的评分 10.00, 数量 1\n"
     ]
    }
   ],
   "source": [
    "# 展示评分与特征关系\n",
    "for category in [\"movies\", \"books\", \"games\"]:\n",
    "    relations = analysis_results[\"rating_feature_relations\"][category]\n",
    "    print(f\"\\n🔗 {category.capitalize()} 评分与特征关系：\")\n",
    "    if \"note\" in relations:\n",
    "        print(f\"  {relations['note']}\")\n",
    "    else:\n",
    "        print(\"  类型（前3个）：\")\n",
    "        for genre, stats in list(relations[\"genre\"].items())[:3]:\n",
    "            douban_str = f\"{stats['douban_mean']:.2f}\" if stats['douban_mean'] is not None else \"N/A\"\n",
    "            my_str = f\"{stats['my_mean']:.2f}\" if stats['my_mean'] is not None else \"N/A\"\n",
    "            print(f\"    - {genre}: 豆瓣 {douban_str}, 我的评分 {my_str}, 数量 {stats['count']}\")\n",
    "        print(\"  年份（前3个）：\")\n",
    "        for year, stats in list(relations[\"year\"].items())[:3]:\n",
    "            douban_str = f\"{stats['douban_mean']:.2f}\" if stats['douban_mean'] is not None else \"N/A\"\n",
    "            my_str = f\"{stats['my_mean']:.2f}\" if stats['my_mean'] is not None else \"N/A\"\n",
    "            print(f\"    - {year}: 豆瓣 {douban_str}, 我的评分 {my_str}, 数量 {stats['count']}\")\n",
    "        if relations.get(\"country\"):\n",
    "            print(\"  国家/地区（前3个）：\")\n",
    "            for country, stats in list(relations[\"country\"].items())[:3]:\n",
    "                douban_str = f\"{stats['douban_mean']:.2f}\" if stats['douban_mean'] is not None else \"N/A\"\n",
    "                my_str = f\"{stats['my_mean']:.2f}\" if stats['my_mean'] is not None else \"N/A\"\n",
    "                print(f\"    - {country}: 豆瓣 {douban_str}, 我的评分 {my_str}, 数量 {stats['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 兴趣周期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_interest_cycles(df, category, sheet_name):\n",
    "    cycles = {}\n",
    "    if df.empty or '创建时间' not in df.columns:\n",
    "        return {\"note\": f\"{sheet_name} 数据为空或缺少‘创建时间’列\"}\n",
    "    \n",
    "    df = df.copy()  # 避免修改原始数据\n",
    "    try:\n",
    "        df['创建时间'] = pd.to_datetime(df['创建时间'], errors='coerce')\n",
    "        if df['创建时间'].isna().all():\n",
    "            return {\"note\": f\"{sheet_name} 的‘创建时间’列无效\"}\n",
    "        df['季度'] = df['创建时间'].dt.to_period('Q')\n",
    "        cycle_counts = df['季度'].value_counts().sort_index()\n",
    "        cycles = {str(k): int(v) for k, v in cycle_counts.items() if pd.notna(k)}\n",
    "        if not cycles:\n",
    "            return {\"note\": f\"{sheet_name} 无有效季度数据\"}\n",
    "    except Exception as e:\n",
    "        return {\"note\": f\"{sheet_name} 处理‘创建时间’失败: {str(e)}\"}\n",
    "    \n",
    "    return cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析兴趣周期（包括所有 sheet）\n",
    "analysis_results[\"interest_cycles\"] = {}  # 确保初始化\n",
    "for category, sheets in [\n",
    "    (\"movies\", [\"想看\", \"看过\", \"所有影视作品\"]),\n",
    "    (\"books\", [\"想读\", \"读过\", \"所有图书\"]),\n",
    "    (\"games\", [\"想玩\", \"在玩\", \"玩过\", \"所有游戏\"])\n",
    "]:\n",
    "    analysis_results[\"interest_cycles\"][category] = {}\n",
    "    for sheet in sheets:\n",
    "        if sheet in cleaned_data and not cleaned_data[sheet].empty:\n",
    "            # print(f\"  分析 {sheet}（记录数：{len(cleaned_data[sheet])}）\")\n",
    "            result = analyze_interest_cycles(cleaned_data[sheet], category, sheet)\n",
    "            analysis_results[\"interest_cycles\"][category][sheet] = result\n",
    "            # print(f\"    结果：{result}\")\n",
    "        elif sheet.startswith(\"所有\"):\n",
    "            # print(f\"  合并 {sheet}...\")\n",
    "            combined_df = pd.concat(\n",
    "                [cleaned_data[s] for s in sheets[:-1] if s in cleaned_data and not cleaned_data[s].empty],\n",
    "                ignore_index=True\n",
    "            )\n",
    "            if combined_df.empty:\n",
    "                analysis_results[\"interest_cycles\"][category][sheet] = {\"note\": f\"{sheet} 合并数据为空\"}\n",
    "                # print(f\"    结果：{sheet} 合并数据为空\")\n",
    "            else:\n",
    "                # print(f\"    合并记录数：{len(combined_df)}\")\n",
    "                result = analyze_interest_cycles(combined_df, category, sheet)\n",
    "                analysis_results[\"interest_cycles\"][category][sheet] = result\n",
    "                # print(f\"    结果：{result}\")\n",
    "        else:\n",
    "            analysis_results[\"interest_cycles\"][category][sheet] = {\"note\": f\"未找到 {sheet} 数据或数据为空\"}\n",
    "            # print(f\"    结果：未找到 {sheet} 数据或数据为空\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📅 展示兴趣周期结果：\n",
      "\n",
      "📅 Movies 兴趣周期：\n",
      "  想看（前3个季度）：\n",
      "    - 2021Q1: 1 条记录\n",
      "    - 2021Q3: 1 条记录\n",
      "    - 2021Q4: 5 条记录\n",
      "  看过（前3个季度）：\n",
      "    - 2021Q1: 2 条记录\n",
      "    - 2021Q4: 21 条记录\n",
      "    - 2022Q1: 14 条记录\n",
      "  所有影视作品（前3个季度）：\n",
      "    - 2021Q1: 3 条记录\n",
      "    - 2021Q3: 1 条记录\n",
      "    - 2021Q4: 26 条记录\n",
      "\n",
      "📅 Books 兴趣周期：\n",
      "  想读（前3个季度）：\n",
      "    - 2021Q4: 1 条记录\n",
      "    - 2022Q2: 9 条记录\n",
      "    - 2022Q3: 3 条记录\n",
      "  读过（前3个季度）：\n",
      "    - 2022Q3: 5 条记录\n",
      "    - 2023Q2: 5 条记录\n",
      "    - 2023Q3: 1 条记录\n",
      "  所有图书（前3个季度）：\n",
      "    - 2021Q4: 1 条记录\n",
      "    - 2022Q2: 9 条记录\n",
      "    - 2022Q3: 8 条记录\n",
      "\n",
      "📅 Games 兴趣周期：\n",
      "  想玩（前3个季度）：\n",
      "    - 2025Q2: 3 条记录\n",
      "  在玩（前3个季度）：\n",
      "    - 2025Q2: 2 条记录\n",
      "  玩过（前3个季度）：\n",
      "    - 2025Q2: 15 条记录\n",
      "  所有游戏（前3个季度）：\n",
      "    - 2025Q2: 20 条记录\n"
     ]
    }
   ],
   "source": [
    "# 展示兴趣周期\n",
    "print(\"\\n📅 展示兴趣周期结果：\")\n",
    "for category in [\"movies\", \"books\", \"games\"]:\n",
    "    cycles = analysis_results[\"interest_cycles\"].get(category, {})\n",
    "    print(f\"\\n📅 {category.capitalize()} 兴趣周期：\")\n",
    "    if not cycles:\n",
    "        print(f\"  错误：{category} 兴趣周期数据缺失\")\n",
    "        continue\n",
    "    for sheet, periods in cycles.items():\n",
    "        print(f\"  {sheet}（前3个季度）：\")\n",
    "        if periods is None:\n",
    "            print(f\"    错误：{sheet} 数据为 None\")\n",
    "        elif isinstance(periods, dict) and \"note\" in periods:\n",
    "            print(f\"    {periods['note']}\")\n",
    "        elif isinstance(periods, dict):\n",
    "            for period, count in list(periods.items())[:3]:\n",
    "                print(f\"    - {period}: {count} 条记录\")\n",
    "        else:\n",
    "            print(f\"    错误：{sheet} 数据格式无效（{type(periods)}）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 消费速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_consumption_speed(df, sheet_name):\n",
    "    speed = {\"yearly\": {}, \"quarterly\": {}}\n",
    "    if df.empty or '创建时间' not in df.columns:\n",
    "        return {\"note\": f\"{sheet_name} 数据为空或缺少‘创建时间’列\"}\n",
    "    \n",
    "    df = df.copy()  # 避免修改原始数据\n",
    "    try:\n",
    "        df['创建时间'] = pd.to_datetime(df['创建时间'], errors='coerce')\n",
    "        if df['创建时间'].isna().all():\n",
    "            return {\"note\": f\"{sheet_name} 的‘创建时间’列无效\"}\n",
    "        df['年份'] = df['创建时间'].dt.year\n",
    "        df['季度'] = df['创建时间'].dt.to_period('Q')\n",
    "        yearly_counts = df['年份'].value_counts().sort_index()\n",
    "        quarterly_counts = df['季度'].value_counts().sort_index()\n",
    "        speed[\"yearly\"] = {str(k): int(v) for k, v in yearly_counts.items() if pd.notna(k)}\n",
    "        speed[\"quarterly\"] = {str(k): int(v) for k, v in quarterly_counts.items() if pd.notna(k)}\n",
    "        if not speed[\"yearly\"] and not speed[\"quarterly\"]:\n",
    "            return {\"note\": f\"{sheet_name} 无有效年份或季度数据\"}\n",
    "    except Exception as e:\n",
    "        return {\"note\": f\"{sheet_name} 处理‘创建时间’失败: {str(e)}\"}\n",
    "    \n",
    "    return speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析消费速度\n",
    "analysis_results[\"consumption_speed\"] = {}  # 确保初始化\n",
    "for category, sheet in [(\"movies\", \"看过\"), (\"books\", \"读过\"), (\"games\", \"玩过\")]:\n",
    "    analysis_results[\"consumption_speed\"][category] = {}\n",
    "    # print(f\"\\n处理 {category} 消费速度：\")\n",
    "    if sheet in cleaned_data and not cleaned_data[sheet].empty:\n",
    "        # print(f\"  分析 {sheet}（记录数：{len(cleaned_data[sheet])}）\")\n",
    "        result = analyze_consumption_speed(cleaned_data[sheet], sheet)\n",
    "        analysis_results[\"consumption_speed\"][category] = result\n",
    "        # print(f\"    结果：{result}\")\n",
    "    else:\n",
    "        analysis_results[\"consumption_speed\"][category] = {\"note\": f\"未找到 {sheet} 数据或数据为空\"}\n",
    "        # print(f\"    结果：未找到 {sheet} 数据或数据为空\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Movies 消费速度：\n",
      "  年均（前3年）：\n",
      "    - 2021: 23 条\n",
      "    - 2022: 92 条\n",
      "    - 2023: 43 条\n",
      "  季均（前3个季度）：\n",
      "    - 2021Q1: 2 条\n",
      "    - 2021Q4: 21 条\n",
      "    - 2022Q1: 14 条\n",
      "\n",
      "🚀 Books 消费速度：\n",
      "  年均（前3年）：\n",
      "    - 2022: 5 条\n",
      "    - 2023: 7 条\n",
      "    - 2024: 12 条\n",
      "  季均（前3个季度）：\n",
      "    - 2022Q3: 5 条\n",
      "    - 2023Q2: 5 条\n",
      "    - 2023Q3: 1 条\n",
      "\n",
      "🚀 Games 消费速度：\n",
      "  年均（前3年）：\n",
      "    - 2025: 15 条\n",
      "  季均（前3个季度）：\n",
      "    - 2025Q2: 15 条\n"
     ]
    }
   ],
   "source": [
    "# 展示消费速度\n",
    "for category in [\"movies\", \"books\", \"games\"]:\n",
    "    speed = analysis_results[\"consumption_speed\"].get(category, None)\n",
    "    print(f\"\\n🚀 {category.capitalize()} 消费速度：\")\n",
    "    if speed is None:\n",
    "        print(f\"  错误：{category} 消费速度数据缺失\")\n",
    "    elif isinstance(speed, dict) and \"note\" in speed:\n",
    "        print(f\"  {speed['note']}\")\n",
    "    elif isinstance(speed, dict):\n",
    "        print(\"  年均（前3年）：\")\n",
    "        for year, count in list(speed[\"yearly\"].items())[:3]:\n",
    "            print(f\"    - {year}: {count} 条\")\n",
    "        print(\"  季均（前3个季度）：\")\n",
    "        for period, count in list(speed[\"quarterly\"].items())[:3]:\n",
    "            print(f\"    - {period}: {count} 条\")\n",
    "    else:\n",
    "        print(f\"  错误：{category} 数据格式无效（{type(speed)}）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 类型共现网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_genre_cooccurrence(df, category):\n",
    "    cooccurrence = {}\n",
    "    if '类型' in df.columns:\n",
    "        for types in df['类型'].dropna():\n",
    "            if isinstance(types, list):\n",
    "                for g1, g2 in combinations(sorted(types), 2):\n",
    "                    pair = f\"{g1}-{g2}\"\n",
    "                    cooccurrence[pair] = cooccurrence.get(pair, 0) + 1\n",
    "    return {k: {\"count\": v, \"genres\": k.split(\"-\")} for k, v in cooccurrence.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 分析类型共现网络（使用合并数据）\n",
    "for category, sheets in [\n",
    "    (\"movies\", [\"想看\", \"看过\"]),\n",
    "]:\n",
    "    combined_df = pd.concat([cleaned_data[s] for s in sheets if s in cleaned_data], ignore_index=True)\n",
    "    analysis_results[\"genre_cooccurrence\"][category] = analyze_genre_cooccurrence(combined_df, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌐 Movies 类型共现网络（前3对）：\n",
      "    - 剧情-犯罪: 共现 31 次\n",
      "    - 动作-惊悚: 共现 16 次\n",
      "    - 动作-犯罪: 共现 14 次\n"
     ]
    }
   ],
   "source": [
    "# 展示类型共现网络\n",
    "for category in [\"movies\"]:\n",
    "    cooccurrence = analysis_results[\"genre_cooccurrence\"][category]\n",
    "    print(f\"\\n🌐 {category.capitalize()} 类型共现网络（前3对）：\")\n",
    "    for pair, stats in list(cooccurrence.items())[:3]:\n",
    "        print(f\"    - {pair}: 共现 {stats['count']} 次\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 保存分析结果到 JSON**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "调试：准备保存高级分析结果到 JSON\n",
      "保存高级分析结果到 ..\\data\\advanced_analysis_results\\advanced_analysis_results.json\n",
      "\n",
      "🔍 高级分析完成！\n"
     ]
    }
   ],
   "source": [
    "json_path = base_output_dir / \"advanced_analysis_results.json\"\n",
    "try:\n",
    "    print(f\"\\n调试：准备保存高级分析结果到 JSON\")\n",
    "    with open(json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(analysis_results, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"保存高级分析结果到 {json_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"保存高级分析结果失败: {str(e)}\")\n",
    "    print(\"调试：analysis_results 示例内容：\")\n",
    "    print(json.dumps({\"rating_trends\": analysis_results[\"rating_trends\"]}, ensure_ascii=False, indent=2))\n",
    "\n",
    "print(\"\\n🔍 高级分析完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
