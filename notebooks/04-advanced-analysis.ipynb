{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 å¤„ç†å‰çš„å‡†å¤‡**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 å¯¼å…¥å¿…è¦çš„åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åˆ›å»ºæˆ–ç¡®è®¤ ..\\data\\advanced_analysis_results ç›®å½•æˆåŠŸ\n",
      "âœ… æˆåŠŸåŠ è½½ cleaned_data\n"
     ]
    }
   ],
   "source": [
    "input_path = Path('../data/interim/cleaned_data.pkl')\n",
    "base_output_dir = Path(\"../data/advanced_analysis_results\")\n",
    "\n",
    "# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨\n",
    "try:\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "    print(f\"åˆ›å»ºæˆ–ç¡®è®¤ {base_output_dir} ç›®å½•æˆåŠŸ\")\n",
    "except Exception as e:\n",
    "    print(f\"åˆ›å»º {base_output_dir} ç›®å½•å¤±è´¥: {e}\")\n",
    "    exit()\n",
    "\n",
    "# åŠ è½½ cleaned_data\n",
    "input_path = Path('../data/interim/cleaned_data.pkl')\n",
    "if input_path.exists():\n",
    "    with open(input_path, 'rb') as f:\n",
    "        cleaned_data = pickle.load(f)\n",
    "    print(\"âœ… æˆåŠŸåŠ è½½ cleaned_data\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"æœªæ‰¾åˆ° cleaned_data.pklï¼Œè¯·å…ˆè¿è¡Œ 02-cleaning.ipynb å¹¶ä¿å­˜æ•°æ®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 åˆå§‹åŒ–åˆ†æç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results = {\n",
    "    \"rating_trends\": {},\n",
    "    \"rating_feature_relations\": {},\n",
    "    \"interest_cycles\": {},\n",
    "    \"consumption_speed\": {},\n",
    "    \"genre_cooccurrence\": {},\n",
    "    \"rating_prediction\": {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 åˆ†æå¤„ç†**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 è¯„åˆ†è¶‹åŠ¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_rating_trends(df, category, sheet_name):\n",
    "    trends = {\"douban_rating\": {}, \"my_rating\": {}}\n",
    "    if 'åˆ›å»ºæ—¶é—´' in df.columns and 'è±†ç“£è¯„åˆ†' in df.columns:\n",
    "        df['åˆ›å»ºæ—¶é—´'] = pd.to_datetime(df['åˆ›å»ºæ—¶é—´'], errors='coerce')\n",
    "        df['å­£åº¦'] = df['åˆ›å»ºæ—¶é—´'].dt.to_period('Q')\n",
    "        # è±†ç“£è¯„åˆ†\n",
    "        douban_trend = df.groupby('å­£åº¦')['è±†ç“£è¯„åˆ†'].agg(['mean', 'count']).dropna()\n",
    "        trends[\"douban_rating\"] = {str(k): {\"mean\": float(v['mean']), \"count\": int(v['count'])} for k, v in douban_trend.iterrows()}\n",
    "        # æˆ‘çš„è¯„åˆ†ï¼ˆ10åˆ†åˆ¶ï¼‰\n",
    "        if 'æˆ‘çš„è¯„åˆ†' in df.columns:\n",
    "            df['æˆ‘çš„è¯„åˆ†_10'] = pd.to_numeric(df['æˆ‘çš„è¯„åˆ†'], errors='coerce') * 2\n",
    "            my_trend = df.groupby('å­£åº¦')['æˆ‘çš„è¯„åˆ†_10'].agg(['mean', 'count']).dropna()\n",
    "            trends[\"my_rating\"] = {str(k): {\"mean\": float(v['mean']), \"count\": int(v['count'])} for k, v in my_trend.iterrows()}\n",
    "    return trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†æè¯„åˆ†è¶‹åŠ¿\n",
    "for category, sheet in [(\"movies\", \"çœ‹è¿‡\"), (\"books\", \"è¯»è¿‡\"), (\"games\", \"ç©è¿‡\")]:\n",
    "    if sheet in cleaned_data:\n",
    "        analysis_results[\"rating_trends\"][category] = analyze_rating_trends(cleaned_data[sheet], category, sheet)\n",
    "    else:\n",
    "        analysis_results[\"rating_trends\"][category] = {\"note\": f\"æœªæ‰¾åˆ° {sheet} æ•°æ®\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ˆ Movies è¯„åˆ†è¶‹åŠ¿ï¼š\n",
      "  è±†ç“£è¯„åˆ†ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2021Q1: å¹³å‡ 8.45, æ•°é‡ 2\n",
      "    - 2021Q4: å¹³å‡ 8.21, æ•°é‡ 21\n",
      "    - 2022Q1: å¹³å‡ 8.52, æ•°é‡ 14\n",
      "  æˆ‘çš„è¯„åˆ†ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2021Q1: å¹³å‡ 10.00, æ•°é‡ 2\n",
      "    - 2021Q4: å¹³å‡ 9.33, æ•°é‡ 21\n",
      "    - 2022Q1: å¹³å‡ 9.14, æ•°é‡ 14\n",
      "\n",
      "ğŸ“ˆ Books è¯„åˆ†è¶‹åŠ¿ï¼š\n",
      "  è±†ç“£è¯„åˆ†ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2022Q3: å¹³å‡ 8.38, æ•°é‡ 5\n",
      "    - 2023Q2: å¹³å‡ 8.36, æ•°é‡ 5\n",
      "    - 2023Q3: å¹³å‡ 9.10, æ•°é‡ 1\n",
      "  æˆ‘çš„è¯„åˆ†ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2022Q3: å¹³å‡ 9.60, æ•°é‡ 5\n",
      "    - 2023Q2: å¹³å‡ 8.00, æ•°é‡ 5\n",
      "    - 2023Q3: å¹³å‡ 8.00, æ•°é‡ 1\n",
      "\n",
      "ğŸ“ˆ Games è¯„åˆ†è¶‹åŠ¿ï¼š\n",
      "  è±†ç“£è¯„åˆ†ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2025Q2: å¹³å‡ 8.70, æ•°é‡ 15\n",
      "  æˆ‘çš„è¯„åˆ†ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2025Q2: å¹³å‡ 9.47, æ•°é‡ 15\n"
     ]
    }
   ],
   "source": [
    "# å±•ç¤ºè¯„åˆ†è¶‹åŠ¿\n",
    "for category in [\"movies\", \"books\", \"games\"]:\n",
    "    trends = analysis_results[\"rating_trends\"][category]\n",
    "    print(f\"\\nğŸ“ˆ {category.capitalize()} è¯„åˆ†è¶‹åŠ¿ï¼š\")\n",
    "    if \"note\" in trends:\n",
    "        print(f\"  {trends['note']}\")\n",
    "    else:\n",
    "        print(\"  è±†ç“£è¯„åˆ†ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\")\n",
    "        for period, stats in list(trends[\"douban_rating\"].items())[:3]:\n",
    "            print(f\"    - {period}: å¹³å‡ {stats['mean']:.2f}, æ•°é‡ {stats['count']}\")\n",
    "        print(\"  æˆ‘çš„è¯„åˆ†ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\")\n",
    "        for period, stats in list(trends[\"my_rating\"].items())[:3]:\n",
    "            print(f\"    - {period}: å¹³å‡ {stats['mean']:.2f}, æ•°é‡ {stats['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 è¯„åˆ†ä¸ç‰¹å¾å…³ç³»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_rating_features(df, category, sheet_name):\n",
    "    features = {\"genre\": {}, \"year\": {}, \"country\": {}}\n",
    "    if df.empty:\n",
    "        return features\n",
    "    \n",
    "    # ç±»å‹\n",
    "    if 'ç±»å‹' in df.columns:\n",
    "        df_exploded = df.explode('ç±»å‹')\n",
    "        genre_stats = df_exploded.groupby('ç±»å‹').agg({\n",
    "            'è±†ç“£è¯„åˆ†': [('mean', 'mean'), ('count', 'count')],\n",
    "            'æˆ‘çš„è¯„åˆ†': [('my_mean', lambda x: (pd.to_numeric(x, errors='coerce') * 2).mean())]\n",
    "        }).dropna()\n",
    "        for genre, stats in genre_stats.iterrows():\n",
    "            features[\"genre\"][genre] = {\n",
    "                \"douban_mean\": float(stats[('è±†ç“£è¯„åˆ†', 'mean')]) if not pd.isna(stats[('è±†ç“£è¯„åˆ†', 'mean')]) else None,\n",
    "                \"my_mean\": float(stats[('æˆ‘çš„è¯„åˆ†', 'my_mean')]) if not pd.isna(stats[('æˆ‘çš„è¯„åˆ†', 'my_mean')]) else None,\n",
    "                \"count\": int(stats[('è±†ç“£è¯„åˆ†', 'count')])\n",
    "            }\n",
    "    \n",
    "    # å¹´ä»½ï¼ˆå›¾ä¹¦ç”¨å‡ºç‰ˆå¹´ä»½ï¼‰\n",
    "    year_col = 'å‡ºç‰ˆå¹´ä»½' if category == \"books\" else 'å¹´ä»½' if category == \"movies\" else 'å‘å”®æ—¶é—´'\n",
    "    if year_col in df.columns:\n",
    "        if year_col == 'å‘å”®æ—¶é—´':\n",
    "            df['å‘å”®å¹´ä»½'] = pd.to_datetime(df['å‘å”®æ—¶é—´'], errors='coerce').dt.year\n",
    "            year_col = 'å‘å”®å¹´ä»½'\n",
    "        year_stats = df.groupby(year_col).agg({\n",
    "            'è±†ç“£è¯„åˆ†': [('mean', 'mean'), ('count', 'count')],\n",
    "            'æˆ‘çš„è¯„åˆ†': [('my_mean', lambda x: (pd.to_numeric(x, errors='coerce') * 2).mean())]\n",
    "        }).dropna()\n",
    "        for year, stats in year_stats.iterrows():\n",
    "            features[\"year\"][str(year)] = {\n",
    "                \"douban_mean\": float(stats[('è±†ç“£è¯„åˆ†', 'mean')]) if not pd.isna(stats[('è±†ç“£è¯„åˆ†', 'mean')]) else None,\n",
    "                \"my_mean\": float(stats[('æˆ‘çš„è¯„åˆ†', 'my_mean')]) if not pd.isna(stats[('æˆ‘çš„è¯„åˆ†', 'my_mean')]) else None,\n",
    "                \"count\": int(stats[('è±†ç“£è¯„åˆ†', 'count')])\n",
    "            }\n",
    "    \n",
    "    # å›½å®¶/åœ°åŒºï¼ˆä»…å½±è§†ï¼‰\n",
    "    if category == \"movies\" and 'å›½å®¶/åœ°åŒº' in df.columns:\n",
    "        df_exploded = df.explode('å›½å®¶/åœ°åŒº')\n",
    "        country_stats = df_exploded.groupby('å›½å®¶/åœ°åŒº').agg({\n",
    "            'è±†ç“£è¯„åˆ†': [('mean', 'mean'), ('count', 'count')],\n",
    "            'æˆ‘çš„è¯„åˆ†': [('my_mean', lambda x: (pd.to_numeric(x, errors='coerce') * 2).mean())]\n",
    "        }).dropna()\n",
    "        for country, stats in country_stats.iterrows():\n",
    "            features[\"country\"][country] = {\n",
    "                \"douban_mean\": float(stats[('è±†ç“£è¯„åˆ†', 'mean')]) if not pd.isna(stats[('è±†ç“£è¯„åˆ†', 'mean')]) else None,\n",
    "                \"my_mean\": float(stats[('æˆ‘çš„è¯„åˆ†', 'my_mean')]) if not pd.isna(stats[('æˆ‘çš„è¯„åˆ†', 'my_mean')]) else None,\n",
    "                \"count\": int(stats[('è±†ç“£è¯„åˆ†', 'count')])\n",
    "            }\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# åˆ†æè¯„åˆ†ä¸ç‰¹å¾å…³ç³»\n",
    "for category, sheet in [(\"movies\", \"çœ‹è¿‡\"), (\"books\", \"è¯»è¿‡\"), (\"games\", \"ç©è¿‡\")]:\n",
    "    if sheet in cleaned_data:\n",
    "        analysis_results[\"rating_feature_relations\"][category] = analyze_rating_features(cleaned_data[sheet], category, sheet)\n",
    "    else:\n",
    "        analysis_results[\"rating_feature_relations\"][category] = {\"note\": f\"æœªæ‰¾åˆ° {sheet} æ•°æ®\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”— Movies è¯„åˆ†ä¸ç‰¹å¾å…³ç³»ï¼š\n",
      "  ç±»å‹ï¼ˆå‰3ä¸ªï¼‰ï¼š\n",
      "    - ä¼ è®°: è±†ç“£ 8.24, æˆ‘çš„è¯„åˆ† 8.67, æ•°é‡ 9\n",
      "    - å„¿ç«¥: è±†ç“£ 7.20, æˆ‘çš„è¯„åˆ† 10.00, æ•°é‡ 1\n",
      "    - å†’é™©: è±†ç“£ 7.60, æˆ‘çš„è¯„åˆ† 8.25, æ•°é‡ 48\n",
      "  å¹´ä»½ï¼ˆå‰3ä¸ªï¼‰ï¼š\n",
      "    - 1994: è±†ç“£ 9.60, æˆ‘çš„è¯„åˆ† 10.00, æ•°é‡ 2\n",
      "    - 1997: è±†ç“£ 9.15, æˆ‘çš„è¯„åˆ† 10.00, æ•°é‡ 2\n",
      "    - 1998: è±†ç“£ 9.35, æˆ‘çš„è¯„åˆ† 9.00, æ•°é‡ 2\n",
      "  å›½å®¶/åœ°åŒºï¼ˆå‰3ä¸ªï¼‰ï¼š\n",
      "    - ä¸­å›½å°æ¹¾: è±†ç“£ 8.14, æˆ‘çš„è¯„åˆ† 9.20, æ•°é‡ 5\n",
      "    - ä¸­å›½å¤§é™†: è±†ç“£ 7.32, æˆ‘çš„è¯„åˆ† 8.38, æ•°é‡ 68\n",
      "    - ä¸­å›½é¦™æ¸¯: è±†ç“£ 7.28, æˆ‘çš„è¯„åˆ† 8.42, æ•°é‡ 19\n",
      "\n",
      "ğŸ”— Books è¯„åˆ†ä¸ç‰¹å¾å…³ç³»ï¼š\n",
      "  ç±»å‹ï¼ˆå‰3ä¸ªï¼‰ï¼š\n",
      "  å¹´ä»½ï¼ˆå‰3ä¸ªï¼‰ï¼š\n",
      "    - 2003: è±†ç“£ 9.00, æˆ‘çš„è¯„åˆ† 10.00, æ•°é‡ 2\n",
      "    - 2006: è±†ç“£ 9.10, æˆ‘çš„è¯„åˆ† 10.00, æ•°é‡ 1\n",
      "    - 2007: è±†ç“£ 8.10, æˆ‘çš„è¯„åˆ† 10.00, æ•°é‡ 1\n",
      "\n",
      "ğŸ”— Games è¯„åˆ†ä¸ç‰¹å¾å…³ç³»ï¼š\n",
      "  ç±»å‹ï¼ˆå‰3ä¸ªï¼‰ï¼š\n",
      "    - å†’é™©: è±†ç“£ 8.86, æˆ‘çš„è¯„åˆ† 9.20, æ•°é‡ 10\n",
      "    - åŠ¨ä½œ: è±†ç“£ 8.92, æˆ‘çš„è¯„åˆ† 9.50, æ•°é‡ 8\n",
      "    - å°„å‡»: è±†ç“£ 8.83, æˆ‘çš„è¯„åˆ† 9.33, æ•°é‡ 3\n",
      "  å¹´ä»½ï¼ˆå‰3ä¸ªï¼‰ï¼š\n",
      "    - 2007: è±†ç“£ 6.50, æˆ‘çš„è¯„åˆ† 10.00, æ•°é‡ 1\n",
      "    - 2009: è±†ç“£ 9.00, æˆ‘çš„è¯„åˆ† 8.00, æ•°é‡ 1\n",
      "    - 2011: è±†ç“£ 8.60, æˆ‘çš„è¯„åˆ† 10.00, æ•°é‡ 1\n"
     ]
    }
   ],
   "source": [
    "# å±•ç¤ºè¯„åˆ†ä¸ç‰¹å¾å…³ç³»\n",
    "for category in [\"movies\", \"books\", \"games\"]:\n",
    "    relations = analysis_results[\"rating_feature_relations\"][category]\n",
    "    print(f\"\\nğŸ”— {category.capitalize()} è¯„åˆ†ä¸ç‰¹å¾å…³ç³»ï¼š\")\n",
    "    if \"note\" in relations:\n",
    "        print(f\"  {relations['note']}\")\n",
    "    else:\n",
    "        print(\"  ç±»å‹ï¼ˆå‰3ä¸ªï¼‰ï¼š\")\n",
    "        for genre, stats in list(relations[\"genre\"].items())[:3]:\n",
    "            douban_str = f\"{stats['douban_mean']:.2f}\" if stats['douban_mean'] is not None else \"N/A\"\n",
    "            my_str = f\"{stats['my_mean']:.2f}\" if stats['my_mean'] is not None else \"N/A\"\n",
    "            print(f\"    - {genre}: è±†ç“£ {douban_str}, æˆ‘çš„è¯„åˆ† {my_str}, æ•°é‡ {stats['count']}\")\n",
    "        print(\"  å¹´ä»½ï¼ˆå‰3ä¸ªï¼‰ï¼š\")\n",
    "        for year, stats in list(relations[\"year\"].items())[:3]:\n",
    "            douban_str = f\"{stats['douban_mean']:.2f}\" if stats['douban_mean'] is not None else \"N/A\"\n",
    "            my_str = f\"{stats['my_mean']:.2f}\" if stats['my_mean'] is not None else \"N/A\"\n",
    "            print(f\"    - {year}: è±†ç“£ {douban_str}, æˆ‘çš„è¯„åˆ† {my_str}, æ•°é‡ {stats['count']}\")\n",
    "        if relations.get(\"country\"):\n",
    "            print(\"  å›½å®¶/åœ°åŒºï¼ˆå‰3ä¸ªï¼‰ï¼š\")\n",
    "            for country, stats in list(relations[\"country\"].items())[:3]:\n",
    "                douban_str = f\"{stats['douban_mean']:.2f}\" if stats['douban_mean'] is not None else \"N/A\"\n",
    "                my_str = f\"{stats['my_mean']:.2f}\" if stats['my_mean'] is not None else \"N/A\"\n",
    "                print(f\"    - {country}: è±†ç“£ {douban_str}, æˆ‘çš„è¯„åˆ† {my_str}, æ•°é‡ {stats['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 å…´è¶£å‘¨æœŸ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_interest_cycles(df, category, sheet_name):\n",
    "    cycles = {}\n",
    "    if df.empty or 'åˆ›å»ºæ—¶é—´' not in df.columns:\n",
    "        return {\"note\": f\"{sheet_name} æ•°æ®ä¸ºç©ºæˆ–ç¼ºå°‘â€˜åˆ›å»ºæ—¶é—´â€™åˆ—\"}\n",
    "    \n",
    "    df = df.copy()  # é¿å…ä¿®æ”¹åŸå§‹æ•°æ®\n",
    "    try:\n",
    "        df['åˆ›å»ºæ—¶é—´'] = pd.to_datetime(df['åˆ›å»ºæ—¶é—´'], errors='coerce')\n",
    "        if df['åˆ›å»ºæ—¶é—´'].isna().all():\n",
    "            return {\"note\": f\"{sheet_name} çš„â€˜åˆ›å»ºæ—¶é—´â€™åˆ—æ— æ•ˆ\"}\n",
    "        df['å­£åº¦'] = df['åˆ›å»ºæ—¶é—´'].dt.to_period('Q')\n",
    "        cycle_counts = df['å­£åº¦'].value_counts().sort_index()\n",
    "        cycles = {str(k): int(v) for k, v in cycle_counts.items() if pd.notna(k)}\n",
    "        if not cycles:\n",
    "            return {\"note\": f\"{sheet_name} æ— æœ‰æ•ˆå­£åº¦æ•°æ®\"}\n",
    "    except Exception as e:\n",
    "        return {\"note\": f\"{sheet_name} å¤„ç†â€˜åˆ›å»ºæ—¶é—´â€™å¤±è´¥: {str(e)}\"}\n",
    "    \n",
    "    return cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†æå…´è¶£å‘¨æœŸï¼ˆåŒ…æ‹¬æ‰€æœ‰ sheetï¼‰\n",
    "analysis_results[\"interest_cycles\"] = {}  # ç¡®ä¿åˆå§‹åŒ–\n",
    "for category, sheets in [\n",
    "    (\"movies\", [\"æƒ³çœ‹\", \"çœ‹è¿‡\", \"æ‰€æœ‰å½±è§†ä½œå“\"]),\n",
    "    (\"books\", [\"æƒ³è¯»\", \"è¯»è¿‡\", \"æ‰€æœ‰å›¾ä¹¦\"]),\n",
    "    (\"games\", [\"æƒ³ç©\", \"åœ¨ç©\", \"ç©è¿‡\", \"æ‰€æœ‰æ¸¸æˆ\"])\n",
    "]:\n",
    "    analysis_results[\"interest_cycles\"][category] = {}\n",
    "    for sheet in sheets:\n",
    "        if sheet in cleaned_data and not cleaned_data[sheet].empty:\n",
    "            # print(f\"  åˆ†æ {sheet}ï¼ˆè®°å½•æ•°ï¼š{len(cleaned_data[sheet])}ï¼‰\")\n",
    "            result = analyze_interest_cycles(cleaned_data[sheet], category, sheet)\n",
    "            analysis_results[\"interest_cycles\"][category][sheet] = result\n",
    "            # print(f\"    ç»“æœï¼š{result}\")\n",
    "        elif sheet.startswith(\"æ‰€æœ‰\"):\n",
    "            # print(f\"  åˆå¹¶ {sheet}...\")\n",
    "            combined_df = pd.concat(\n",
    "                [cleaned_data[s] for s in sheets[:-1] if s in cleaned_data and not cleaned_data[s].empty],\n",
    "                ignore_index=True\n",
    "            )\n",
    "            if combined_df.empty:\n",
    "                analysis_results[\"interest_cycles\"][category][sheet] = {\"note\": f\"{sheet} åˆå¹¶æ•°æ®ä¸ºç©º\"}\n",
    "                # print(f\"    ç»“æœï¼š{sheet} åˆå¹¶æ•°æ®ä¸ºç©º\")\n",
    "            else:\n",
    "                # print(f\"    åˆå¹¶è®°å½•æ•°ï¼š{len(combined_df)}\")\n",
    "                result = analyze_interest_cycles(combined_df, category, sheet)\n",
    "                analysis_results[\"interest_cycles\"][category][sheet] = result\n",
    "                # print(f\"    ç»“æœï¼š{result}\")\n",
    "        else:\n",
    "            analysis_results[\"interest_cycles\"][category][sheet] = {\"note\": f\"æœªæ‰¾åˆ° {sheet} æ•°æ®æˆ–æ•°æ®ä¸ºç©º\"}\n",
    "            # print(f\"    ç»“æœï¼šæœªæ‰¾åˆ° {sheet} æ•°æ®æˆ–æ•°æ®ä¸ºç©º\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“… å±•ç¤ºå…´è¶£å‘¨æœŸç»“æœï¼š\n",
      "\n",
      "ğŸ“… Movies å…´è¶£å‘¨æœŸï¼š\n",
      "  æƒ³çœ‹ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2021Q1: 1 æ¡è®°å½•\n",
      "    - 2021Q3: 1 æ¡è®°å½•\n",
      "    - 2021Q4: 5 æ¡è®°å½•\n",
      "  çœ‹è¿‡ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2021Q1: 2 æ¡è®°å½•\n",
      "    - 2021Q4: 21 æ¡è®°å½•\n",
      "    - 2022Q1: 14 æ¡è®°å½•\n",
      "  æ‰€æœ‰å½±è§†ä½œå“ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2021Q1: 3 æ¡è®°å½•\n",
      "    - 2021Q3: 1 æ¡è®°å½•\n",
      "    - 2021Q4: 26 æ¡è®°å½•\n",
      "\n",
      "ğŸ“… Books å…´è¶£å‘¨æœŸï¼š\n",
      "  æƒ³è¯»ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2021Q4: 1 æ¡è®°å½•\n",
      "    - 2022Q2: 9 æ¡è®°å½•\n",
      "    - 2022Q3: 3 æ¡è®°å½•\n",
      "  è¯»è¿‡ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2022Q3: 5 æ¡è®°å½•\n",
      "    - 2023Q2: 5 æ¡è®°å½•\n",
      "    - 2023Q3: 1 æ¡è®°å½•\n",
      "  æ‰€æœ‰å›¾ä¹¦ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2021Q4: 1 æ¡è®°å½•\n",
      "    - 2022Q2: 9 æ¡è®°å½•\n",
      "    - 2022Q3: 8 æ¡è®°å½•\n",
      "\n",
      "ğŸ“… Games å…´è¶£å‘¨æœŸï¼š\n",
      "  æƒ³ç©ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2025Q2: 3 æ¡è®°å½•\n",
      "  åœ¨ç©ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2025Q2: 2 æ¡è®°å½•\n",
      "  ç©è¿‡ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2025Q2: 15 æ¡è®°å½•\n",
      "  æ‰€æœ‰æ¸¸æˆï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2025Q2: 20 æ¡è®°å½•\n"
     ]
    }
   ],
   "source": [
    "# å±•ç¤ºå…´è¶£å‘¨æœŸ\n",
    "print(\"\\nğŸ“… å±•ç¤ºå…´è¶£å‘¨æœŸç»“æœï¼š\")\n",
    "for category in [\"movies\", \"books\", \"games\"]:\n",
    "    cycles = analysis_results[\"interest_cycles\"].get(category, {})\n",
    "    print(f\"\\nğŸ“… {category.capitalize()} å…´è¶£å‘¨æœŸï¼š\")\n",
    "    if not cycles:\n",
    "        print(f\"  é”™è¯¯ï¼š{category} å…´è¶£å‘¨æœŸæ•°æ®ç¼ºå¤±\")\n",
    "        continue\n",
    "    for sheet, periods in cycles.items():\n",
    "        print(f\"  {sheet}ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\")\n",
    "        if periods is None:\n",
    "            print(f\"    é”™è¯¯ï¼š{sheet} æ•°æ®ä¸º None\")\n",
    "        elif isinstance(periods, dict) and \"note\" in periods:\n",
    "            print(f\"    {periods['note']}\")\n",
    "        elif isinstance(periods, dict):\n",
    "            for period, count in list(periods.items())[:3]:\n",
    "                print(f\"    - {period}: {count} æ¡è®°å½•\")\n",
    "        else:\n",
    "            print(f\"    é”™è¯¯ï¼š{sheet} æ•°æ®æ ¼å¼æ— æ•ˆï¼ˆ{type(periods)}ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 æ¶ˆè´¹é€Ÿåº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_consumption_speed(df, sheet_name):\n",
    "    speed = {\"yearly\": {}, \"quarterly\": {}}\n",
    "    if df.empty or 'åˆ›å»ºæ—¶é—´' not in df.columns:\n",
    "        return {\"note\": f\"{sheet_name} æ•°æ®ä¸ºç©ºæˆ–ç¼ºå°‘â€˜åˆ›å»ºæ—¶é—´â€™åˆ—\"}\n",
    "    \n",
    "    df = df.copy()  # é¿å…ä¿®æ”¹åŸå§‹æ•°æ®\n",
    "    try:\n",
    "        df['åˆ›å»ºæ—¶é—´'] = pd.to_datetime(df['åˆ›å»ºæ—¶é—´'], errors='coerce')\n",
    "        if df['åˆ›å»ºæ—¶é—´'].isna().all():\n",
    "            return {\"note\": f\"{sheet_name} çš„â€˜åˆ›å»ºæ—¶é—´â€™åˆ—æ— æ•ˆ\"}\n",
    "        df['å¹´ä»½'] = df['åˆ›å»ºæ—¶é—´'].dt.year\n",
    "        df['å­£åº¦'] = df['åˆ›å»ºæ—¶é—´'].dt.to_period('Q')\n",
    "        yearly_counts = df['å¹´ä»½'].value_counts().sort_index()\n",
    "        quarterly_counts = df['å­£åº¦'].value_counts().sort_index()\n",
    "        speed[\"yearly\"] = {str(k): int(v) for k, v in yearly_counts.items() if pd.notna(k)}\n",
    "        speed[\"quarterly\"] = {str(k): int(v) for k, v in quarterly_counts.items() if pd.notna(k)}\n",
    "        if not speed[\"yearly\"] and not speed[\"quarterly\"]:\n",
    "            return {\"note\": f\"{sheet_name} æ— æœ‰æ•ˆå¹´ä»½æˆ–å­£åº¦æ•°æ®\"}\n",
    "    except Exception as e:\n",
    "        return {\"note\": f\"{sheet_name} å¤„ç†â€˜åˆ›å»ºæ—¶é—´â€™å¤±è´¥: {str(e)}\"}\n",
    "    \n",
    "    return speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†ææ¶ˆè´¹é€Ÿåº¦\n",
    "analysis_results[\"consumption_speed\"] = {}  # ç¡®ä¿åˆå§‹åŒ–\n",
    "for category, sheet in [(\"movies\", \"çœ‹è¿‡\"), (\"books\", \"è¯»è¿‡\"), (\"games\", \"ç©è¿‡\")]:\n",
    "    analysis_results[\"consumption_speed\"][category] = {}\n",
    "    # print(f\"\\nå¤„ç† {category} æ¶ˆè´¹é€Ÿåº¦ï¼š\")\n",
    "    if sheet in cleaned_data and not cleaned_data[sheet].empty:\n",
    "        # print(f\"  åˆ†æ {sheet}ï¼ˆè®°å½•æ•°ï¼š{len(cleaned_data[sheet])}ï¼‰\")\n",
    "        result = analyze_consumption_speed(cleaned_data[sheet], sheet)\n",
    "        analysis_results[\"consumption_speed\"][category] = result\n",
    "        # print(f\"    ç»“æœï¼š{result}\")\n",
    "    else:\n",
    "        analysis_results[\"consumption_speed\"][category] = {\"note\": f\"æœªæ‰¾åˆ° {sheet} æ•°æ®æˆ–æ•°æ®ä¸ºç©º\"}\n",
    "        # print(f\"    ç»“æœï¼šæœªæ‰¾åˆ° {sheet} æ•°æ®æˆ–æ•°æ®ä¸ºç©º\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Movies æ¶ˆè´¹é€Ÿåº¦ï¼š\n",
      "  å¹´å‡ï¼ˆå‰3å¹´ï¼‰ï¼š\n",
      "    - 2021: 23 æ¡\n",
      "    - 2022: 92 æ¡\n",
      "    - 2023: 43 æ¡\n",
      "  å­£å‡ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2021Q1: 2 æ¡\n",
      "    - 2021Q4: 21 æ¡\n",
      "    - 2022Q1: 14 æ¡\n",
      "\n",
      "ğŸš€ Books æ¶ˆè´¹é€Ÿåº¦ï¼š\n",
      "  å¹´å‡ï¼ˆå‰3å¹´ï¼‰ï¼š\n",
      "    - 2022: 5 æ¡\n",
      "    - 2023: 7 æ¡\n",
      "    - 2024: 12 æ¡\n",
      "  å­£å‡ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2022Q3: 5 æ¡\n",
      "    - 2023Q2: 5 æ¡\n",
      "    - 2023Q3: 1 æ¡\n",
      "\n",
      "ğŸš€ Games æ¶ˆè´¹é€Ÿåº¦ï¼š\n",
      "  å¹´å‡ï¼ˆå‰3å¹´ï¼‰ï¼š\n",
      "    - 2025: 15 æ¡\n",
      "  å­£å‡ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\n",
      "    - 2025Q2: 15 æ¡\n"
     ]
    }
   ],
   "source": [
    "# å±•ç¤ºæ¶ˆè´¹é€Ÿåº¦\n",
    "for category in [\"movies\", \"books\", \"games\"]:\n",
    "    speed = analysis_results[\"consumption_speed\"].get(category, None)\n",
    "    print(f\"\\nğŸš€ {category.capitalize()} æ¶ˆè´¹é€Ÿåº¦ï¼š\")\n",
    "    if speed is None:\n",
    "        print(f\"  é”™è¯¯ï¼š{category} æ¶ˆè´¹é€Ÿåº¦æ•°æ®ç¼ºå¤±\")\n",
    "    elif isinstance(speed, dict) and \"note\" in speed:\n",
    "        print(f\"  {speed['note']}\")\n",
    "    elif isinstance(speed, dict):\n",
    "        print(\"  å¹´å‡ï¼ˆå‰3å¹´ï¼‰ï¼š\")\n",
    "        for year, count in list(speed[\"yearly\"].items())[:3]:\n",
    "            print(f\"    - {year}: {count} æ¡\")\n",
    "        print(\"  å­£å‡ï¼ˆå‰3ä¸ªå­£åº¦ï¼‰ï¼š\")\n",
    "        for period, count in list(speed[\"quarterly\"].items())[:3]:\n",
    "            print(f\"    - {period}: {count} æ¡\")\n",
    "    else:\n",
    "        print(f\"  é”™è¯¯ï¼š{category} æ•°æ®æ ¼å¼æ— æ•ˆï¼ˆ{type(speed)}ï¼‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 ç±»å‹å…±ç°ç½‘ç»œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_genre_cooccurrence(df, category):\n",
    "    cooccurrence = {}\n",
    "    if 'ç±»å‹' in df.columns:\n",
    "        for types in df['ç±»å‹'].dropna():\n",
    "            if isinstance(types, list):\n",
    "                for g1, g2 in combinations(sorted(types), 2):\n",
    "                    pair = f\"{g1}-{g2}\"\n",
    "                    cooccurrence[pair] = cooccurrence.get(pair, 0) + 1\n",
    "    return {k: {\"count\": v, \"genres\": k.split(\"-\")} for k, v in cooccurrence.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# åˆ†æç±»å‹å…±ç°ç½‘ç»œï¼ˆä½¿ç”¨åˆå¹¶æ•°æ®ï¼‰\n",
    "for category, sheets in [\n",
    "    (\"movies\", [\"æƒ³çœ‹\", \"çœ‹è¿‡\"]),\n",
    "]:\n",
    "    combined_df = pd.concat([cleaned_data[s] for s in sheets if s in cleaned_data], ignore_index=True)\n",
    "    analysis_results[\"genre_cooccurrence\"][category] = analyze_genre_cooccurrence(combined_df, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ Movies ç±»å‹å…±ç°ç½‘ç»œï¼ˆå‰3å¯¹ï¼‰ï¼š\n",
      "    - å‰§æƒ…-çŠ¯ç½ª: å…±ç° 31 æ¬¡\n",
      "    - åŠ¨ä½œ-æƒŠæ‚š: å…±ç° 16 æ¬¡\n",
      "    - åŠ¨ä½œ-çŠ¯ç½ª: å…±ç° 14 æ¬¡\n"
     ]
    }
   ],
   "source": [
    "# å±•ç¤ºç±»å‹å…±ç°ç½‘ç»œ\n",
    "for category in [\"movies\"]:\n",
    "    cooccurrence = analysis_results[\"genre_cooccurrence\"][category]\n",
    "    print(f\"\\nğŸŒ {category.capitalize()} ç±»å‹å…±ç°ç½‘ç»œï¼ˆå‰3å¯¹ï¼‰ï¼š\")\n",
    "    for pair, stats in list(cooccurrence.items())[:3]:\n",
    "        print(f\"    - {pair}: å…±ç° {stats['count']} æ¬¡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 ä¿å­˜åˆ†æç»“æœåˆ° JSON**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "è°ƒè¯•ï¼šå‡†å¤‡ä¿å­˜é«˜çº§åˆ†æç»“æœåˆ° JSON\n",
      "ä¿å­˜é«˜çº§åˆ†æç»“æœåˆ° ..\\data\\advanced_analysis_results\\advanced_analysis_results.json\n",
      "\n",
      "ğŸ” é«˜çº§åˆ†æå®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "json_path = base_output_dir / \"advanced_analysis_results.json\"\n",
    "try:\n",
    "    print(f\"\\nè°ƒè¯•ï¼šå‡†å¤‡ä¿å­˜é«˜çº§åˆ†æç»“æœåˆ° JSON\")\n",
    "    with open(json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(analysis_results, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"ä¿å­˜é«˜çº§åˆ†æç»“æœåˆ° {json_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"ä¿å­˜é«˜çº§åˆ†æç»“æœå¤±è´¥: {str(e)}\")\n",
    "    print(\"è°ƒè¯•ï¼šanalysis_results ç¤ºä¾‹å†…å®¹ï¼š\")\n",
    "    print(json.dumps({\"rating_trends\": analysis_results[\"rating_trends\"]}, ensure_ascii=False, indent=2))\n",
    "\n",
    "print(\"\\nğŸ” é«˜çº§åˆ†æå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
